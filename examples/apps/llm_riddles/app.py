import functools
import inspect
import os
import random
import re

import gradio as gr
from challenges.ch1 import challenge1
from challenges.ch2 import challenge2
from challenges.ch3 import challenge3
from challenges.ch4 import challenge4
from llm import create_model

model_cache = {}

# å®šä¹‰å…³å¡ä¿¡æ¯å’ŒéªŒè¯é€»è¾‘
challenges = [
    challenge1,
    challenge2,
    challenge3,
    challenge4,
]


def get_problem(challenge_idx, problem_idx):
    problems = challenges[challenge_idx]['problems']
    return problems[problem_idx]


def update_challenge_info(current_chapter_index, current_challenge_index):
    return get_problem(current_chapter_index,
                       current_challenge_index)['description']


def update_question_info(current_chapter_index, current_challenge_index):
    global challenges
    current_chapter = challenges[current_chapter_index]
    challenge = get_problem(current_chapter_index, current_challenge_index)
    question_info = f"""\n<center><font size=4>{current_chapter["name"]}""" \
                    f"""</center>\n\n <center><font size=3>{challenge["title"]}</center>"""
    return question_info


def validate_challenge(response, input, state, generate_response):
    print('in validate_challenge')
    assert 'current_chapter_index' in state, 'current_chapter_index not found in state'
    assert 'current_challenge_index' in state, 'current_challenge_index not found in state'
    current_chapter_index = state['current_chapter_index']
    current_challenge_index = state['current_challenge_index']
    # è·å–å½“å‰ç« èŠ‚
    current_chapter = challenges[current_chapter_index]
    # è·å–å½“å‰æŒ‘æˆ˜
    challenge = current_chapter['problems'][current_challenge_index]

    validate_fn = challenge['validator']
    params = inspect.signature(validate_fn).parameters
    if 'generate_response' in params:
        valid_result = validate_fn(response, input, generate_response)
    else:
        valid_result = validate_fn(response, input)

    if valid_result:
        challenge_result = 'æŒ‘æˆ˜æˆåŠŸï¼è¿›å…¥ä¸‹ä¸€å…³ã€‚'
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šæŒ‘æˆ˜åœ¨å½“å‰ç« èŠ‚
        if current_challenge_index < len(current_chapter['problems']) - 1:
            # ç§»åŠ¨åˆ°å½“å‰ç« èŠ‚çš„ä¸‹ä¸€ä¸ªæŒ‘æˆ˜
            current_challenge_index += 1
        else:
            # å¦‚æœå½“å‰ç« èŠ‚çš„æŒ‘æˆ˜å·²ç»å®Œæˆï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªç« èŠ‚
            current_challenge_index = 0
            if current_chapter_index < len(challenges) - 1:
                current_chapter_index += 1
            else:
                challenge_result = 'æ‰€æœ‰æŒ‘æˆ˜å®Œæˆï¼'
    else:
        challenge_result = 'æŒ‘æˆ˜å¤±è´¥ï¼Œè¯·å†è¯•ä¸€æ¬¡ã€‚'
    state['current_chapter_index'] = current_chapter_index
    state['current_challenge_index'] = current_challenge_index
    print('update state: ', state)

    return challenge_result, \
        update_question_info(current_chapter_index, current_challenge_index), \
        update_challenge_info(current_chapter_index, current_challenge_index)


def generate_response(input, model_name):
    if model_name in model_cache:
        model = model_cache[model_name]
    else:
        model = create_model(model_name)
        model_cache[model_name] = model

    try:
        return model(input)
    except RuntimeError as e:
        # if exception happens, print error in log and return empty str
        print('error', e)
        return ''


def on_submit(input, state):
    model_name = 'qwen-plus'
    gen_fn = functools.partial(generate_response, model_name=model_name)
    response = gen_fn(input)
    history = [(input, response)]
    print(history)
    challenge_result, question_info, challenge_info = validate_challenge(
        response, input, state, gen_fn)
    print('validate_challenge done')
    return challenge_result, history, question_info, challenge_info


# Gradioç•Œé¢æ„å»º
block = gr.Blocks()

with block as demo:
    state = gr.State(dict(current_challenge_index=0, current_chapter_index=0))
    current_chapter_index = 0
    current_challenge_index = 0
    gr.Markdown("""<center><font size=6>å®Œè›‹ï¼æˆ‘è¢«LLMåŒ…å›´äº†ï¼</center>""")
    gr.Markdown("""<font size=3>æ¬¢è¿æ¥ç©LLM Riddleså¤åˆ»ç‰ˆï¼šå®Œè›‹ï¼æˆ‘è¢«LLMåŒ…å›´äº†ï¼

ä½ å°†é€šè¿‡æœ¬æ¸¸æˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹äº§ç”Ÿæ›´æ·±åˆ»çš„ç†è§£ã€‚

åœ¨æœ¬æ¸¸æˆä¸­ï¼Œä½ éœ€è¦æ„é€ ä¸€ä¸ªæç»™ä¸€ä¸ªå¤§å‹è¯­è¨€æ¨¡å‹çš„é—®é¢˜ï¼Œä½¿å¾—å®ƒå›å¤çš„ç­”æ¡ˆç¬¦åˆè¦æ±‚ã€‚""")
    question_info = gr.Markdown(
        update_question_info(current_chapter_index, current_challenge_index))
    challenge_info = gr.Textbox(
        value=update_challenge_info(current_chapter_index,
                                    current_challenge_index),
        label='å½“å‰æŒ‘æˆ˜',
        disabled=True)
    challenge_result = gr.Textbox(label='æŒ‘æˆ˜ç»“æœ', disabled=True)
    chatbot = gr.Chatbot(
        lines=8, label='Qwen-max', elem_classes='control-height')
    message = gr.Textbox(lines=2, label='è¾“å…¥')

    with gr.Row():
        submit = gr.Button('ğŸš€ å‘é€')

    submit.click(
        on_submit,
        inputs=[message, state],
        outputs=[challenge_result, chatbot, question_info, challenge_info])

demo.queue(concurrency_count=10).launch(
    height=800, share=True, concurrency_limit=10)
